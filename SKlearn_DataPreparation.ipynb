{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"height:100px;line-height:100px;font-size:46px;background-color:lime;color:white;padding-left:12px;\">\n",
    "    SciKit-Learn\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as mpp\n",
    "import sklearn.datasets as dts\n",
    "from sklearn.impute import SimpleImputer\n",
    "import sklearn.feature_selection as fsl\n",
    "import sklearn.preprocessing as ppr\n",
    "import sklearn.model_selection as msl\n",
    "import sklearn.linear_model as lmd\n",
    "import sklearn.ensemble as ens\n",
    "import sklearn.metrics as mtr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **1) Load Data: import sklearn.datasets as dts OR Manuel**\n",
    "- **2) Cleaning: from sklearn.impute import SimpleImputer OR Manuel**\n",
    "- **3) Features Selection: import sklearn.feature_selection as fsl OR Manuel**\n",
    "- **4) Scalling: import sklearn.preprocessing as ppr OR Manuel**\n",
    "- **5) Spliting: import sklearn.model_selection as msl OR Manuel**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **X = input : X_train, X_test**\n",
    "- **y = output : y_pred, y_true**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IrisData = dts.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IrisData.data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IrisData.target[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IrisData.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IrisData.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(IrisData.data, columns=IrisData.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DigitsData = dts.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [6, 7, 7, 6, 7, 7, 6] #true\n",
    "Y = [6, 6, 7, 6, 6, 6, 7] #prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Meterics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtr.mean_absolute_error(X, Y, multioutput='uniform_average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtr.mean_squared_error(X, Y, multioutput='uniform_average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtr.median_absolute_error(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = mtr.confusion_matrix(X, Y)\n",
    "val\n",
    "#[[TP, FP],\n",
    "# [FN, TN]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = 0\n",
    "vals = []\n",
    "while i < val.shape[0] and j < val.shape[1]:\n",
    "    vals.append(val[i,j])\n",
    "    i += 1\n",
    "    j += 1\n",
    "print(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.heatmap(val, center=True)\n",
    "mpp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mtr.accuracy_score(X, Y) # --------------->  normalize=[True, Flase] default is True\n",
    "b = mtr.accuracy_score(X, Y, normalize=False)\n",
    "a, b\n",
    "#False show onlt True values\n",
    "#True show True values / Total values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtr.recall_score(X, Y, average='micro')   #average = [binary, macro, weighted, samples]\n",
    "#recall score (Sensitivity) = TP / float(TP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtr.precision_score(X, Y, average='micro')   #average = [binary, macro, weighted, samples]\n",
    "# precision score (Specificity) = TP / float(TP + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtr.f1_score(X, Y, average='micro') #average = [binary, macro, weighted, samples]\n",
    "#f1 score = 2 * (precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtr.precision_recall_fscore_support(X, Y, average='micro')\n",
    "#precision_recall_fscore_support(y_true, y_pred, beta=1.0, labels=None, pos_label=1, average=None, sample_weight=None,  \n",
    "#                                warn_for = ('precision’,’recall’, ’f-score’))\n",
    "#Return /precision_score-recall_score-f1score-support/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1 = [0, 1, 1, 0, 0, 1]\n",
    "X1 = [3 , 4, 3, 2, 1, 5]\n",
    "mtr.precision_recall_curve(Y1, X1)\n",
    "#precision_recall_curve(y_true, probas_pred, pos_label=None, sample_weight=None)\n",
    "#Return /precision-recall-thresholds/ just for binary[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = mtr.classification_report(X, Y)\n",
    "#classification_report(y_true, y_pred, labels=None, target_names=None,sample_weight=None, digits=2, output_dict=False)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fpr = 1-specificity  (specificity = precision)\n",
    "#tpr = sensivity   (sensivity = recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_value, tpr_value, thresholds_value = mtr.roc_curve(Y, X, pos_label=2)\n",
    "fpr_value, tpr_value, thresholds_value\n",
    "#Return /fpr-tpr-thresholds/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtr.auc(fpr_value, tpr_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtr.roc_auc_score(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtr.zero_one_loss(X, Y), mtr.zero_one_loss(X, Y, normalize=False)   #normalize=[True, False]\n",
    "#how much algorithm is wrong True = decimal, False=integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_houses = pd.read_csv('C:/Users/asus_r/Desktop/Data Center/Data/SKLearn/houses.csv')\n",
    "df_houses_ = df_houses.drop('long', axis=1)\n",
    "df_houses_.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_houses.apply(lambda x : sum(x.isnull()), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_houses_target = df_houses['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_ = np.random.randint(10, 60, 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sel = fsl.SelectPercentile(score_func=fsl.chi2, percentile=50)\n",
    "Sel.fit_transform(df_houses_.values, df_target_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sel2 = fsl.GenericUnivariateSelect(score_func=fsl.chi2, mode='k_best', param=5) #mod = ['percentile', 'k_best', 'fpr', 'fdr', 'fwe']\n",
    "Sel2.fit_transform(df_houses_.values, df_target_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sel3 = fsl.SelectKBest(score_func=fsl.chi2, k=4)\n",
    "Sel3.fit_transform(df_houses_.values, df_target_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lmd.LinearRegression()\n",
    "model2 = ens.RandomForestRegressor()\n",
    "Sel4 = fsl.SelectFromModel(estimator=model, max_features=None)\n",
    "Sel4.fit_transform(df_houses_.values, df_target_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = df_houses\n",
    "Scaler = ppr.StandardScaler().fit_transform(Data)   #Standardization = (Value - mean) / std'Segma'\n",
    "Scaler.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaler_2 = ppr.MinMaxScaler(feature_range=(0, 1)).fit_transform(Data)     #Normalization = (Value - mean) / range\n",
    "Scaler.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaler_3 = ppr.Normalizer(norm='l1').fit_transform(Data)\n",
    "#norm=['l1', 'l2', 'max']\n",
    "#l1 --> value / sum(values in row) --> [2,3,4] --> 2 / (2+3+4)\n",
    "#l2 --> value / sqrt(sum(valaues**2 in row)) --> [2,3,4] --> 2 / sqrt(square(2) + square(3) + square(4))\n",
    "#max --> value / max(row) --> [2,3,4] --> 2 / max(row)=4\n",
    "Scaler_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaler_4 = ppr.MaxAbsScaler().fit_transform(Data)\n",
    "#value / max(column) --> [2,1,4,6,3,9] --> 2 / max(col)=9\n",
    "Scaler_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaler_5 = ppr.FunctionTransformer(func=lambda x:x, validate=True).fit_transform(Data)\n",
    "#you can use your func or lambda\n",
    "Scaler_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaler_6 = ppr.Binarizer(threshold=200).fit_transform(Data)\n",
    "#if value > threshold --> value = 1\n",
    "#elif value < treshold --> value = 0\n",
    "Scaler_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = [[1, 3, 4],\n",
    "      [3, 5, 1],\n",
    "      [6, 2, 3],\n",
    "      [9, 3, 5]]\n",
    "Scaler_7 = ppr.PolynomialFeatures(degree=2, include_bias=True, interaction_only=False).fit_transform(dt)\n",
    "Scaler_7\n",
    "#[a, b, c] --> [1, a, b, c, a*a, a*b, a*c, b*c, c*c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaler_71 = ppr.PolynomialFeatures(degree=2, include_bias=True, interaction_only=True).fit_transform(dt)\n",
    "Scaler_71\n",
    "#[a, b, c] --> [1, a, b, c, a*b, a*c, b*c] --. without squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = np.random.randint(100, 900, 50).reshape(10, 5), np.random.randint(0, 20, 10)\n",
    "X_test, X_train, y_test, y_train = msl.train_test_split(X, y, test_size=0.60, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = msl.KFold(n_splits=2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [2 3 4 6 9] TEST: [0 1 5 7 8]\n",
      "X_train \n",
      " [[667 575 457 812 350]\n",
      " [364 376 860 353 363]\n",
      " [865 745 181 268 802]\n",
      " [178 604 653 542 758]\n",
      " [296 700 699 437 389]]\n",
      "X_test \n",
      " [[158 306 254 360 447]\n",
      " [771 502 413 308 896]\n",
      " [695 667 248 117 296]\n",
      " [472 133 375 580 387]\n",
      " [764 538 390 354 590]]\n",
      "y_train \n",
      " [17  1 17  9  2]\n",
      "y_test \n",
      " [ 3 10  1 17  0]\n",
      "TRAIN: [0 1 5 7 8] TEST: [2 3 4 6 9]\n",
      "X_train \n",
      " [[158 306 254 360 447]\n",
      " [771 502 413 308 896]\n",
      " [695 667 248 117 296]\n",
      " [472 133 375 580 387]\n",
      " [764 538 390 354 590]]\n",
      "X_test \n",
      " [[667 575 457 812 350]\n",
      " [364 376 860 353 363]\n",
      " [865 745 181 268 802]\n",
      " [178 604 653 542 758]\n",
      " [296 700 699 437 389]]\n",
      "y_train \n",
      " [ 3 10  1 17  0]\n",
      "y_test \n",
      " [17  1 17  9  2]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print('X_train \\n' , X_train)\n",
    "    print('X_test \\n' , X_test)\n",
    "    print('y_train \\n' ,y_train)\n",
    "    print('y_test \\n' , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rkf = msl.RepeatedKFold(n_splits=3, n_repeats=4, random_state=42)\n",
    "Skf = msl.StratifiedKFold(n_splits=4)\n",
    "RSkf = msl.RepeatedStratifiedKFold(n_splits=3, n_repeats=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1O = msl.LeaveOneOut()\n",
    "LPO = msl.LeavePOut(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "Shf = msl.ShuffleSplit(n_splits=6, test_size=0.3, random_state=42)\n",
    "SSh = msl.StratifiedShuffleSplit(n_splits=8, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tsr = msl.TimeSeriesSplit(n_splits=5, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"height:240px;line-height:100px;font-size:64px;background-color:cyan;color:white;padding:20px auto;text-align:center;border:2px outset gold;border-radius:8px;\">\n",
    "    Created by:<br/> <code>Tarek Ghajary</code>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
